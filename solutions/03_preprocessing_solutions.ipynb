{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dbac37",
   "metadata": {},
   "source": [
    "## Challenge 1: Fitting preprocessing functions\n",
    "\n",
    "The simple imputer, normalization and one-hot-encoding rely on sklearn functions that are fit to a data set. \n",
    "\n",
    "1) What is being fit for each of the three functions?\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "    1) One Hot Encoding - Levels for each categorical variable\n",
    "    \n",
    "    2) Standard Scaler - Mean / std deviation for each column\n",
    "    \n",
    "    3) Simple Imputer - Mean for each column\n",
    "    \n",
    "\n",
    "When we are preprocessing data we have a few options: \n",
    "1) Fit on the whole data set\n",
    "2) Fit on the training data\n",
    "3) Fit on the testing data\n",
    "\n",
    "Which of the above methods would you use and why?\n",
    "\n",
    "**Solution:** Best practice is to fit on the training data. This avoids **data leakage** or influence of test data information on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b2692",
   "metadata": {},
   "source": [
    "## Challenge 2: Order of Preprocessing\n",
    "\n",
    "In the preprocessing we did the following steps: \n",
    "\n",
    "1) Null values\n",
    "2) One-hot-encoding\n",
    "3) Imputation\n",
    "4) Normalization\n",
    "\n",
    "Now, consider that we change the order of the steps in the following ways. What effect might that have on the algorithms?\n",
    "**Hint**: Try copying the code from above and trying it out!\n",
    "\n",
    "- One-Hot-Encoding before Null Values - This will include null values as levels in one-hot-encoding\n",
    "- Normalization before Null values - This may cause errors due to null values.\n",
    "\n",
    "**Bonus:** Are there any other switches in order that might affect preprocessing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde87a2",
   "metadata": {},
   "source": [
    "## Challenge 3: Preprocessing and regularization\n",
    "\n",
    "We are preprocessing data in preparation for a classification task down the line. However, preprocessing also applies to regression. \n",
    "\n",
    "Consider the regularization task applied in the previous notebook. How might the preprocessing steps affect the performance of regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83175bef",
   "metadata": {},
   "source": [
    "Regularization penalizes large model coefficients, so preprocessing strongly affects how that penalty behaves. If your features aren't on the same scale, one variable's coefficients can appear much larger simply because its values are larger in magnitude, not because itâ€™s more important. That makes regularization (L1 or L2) unfairly penalize some features more than others and can distort the model.\n",
    "\n",
    "Standardizing or normalizing features before applying regularization ensures the penalty is applied uniformly, making the regularization strength meaningful and improving model stability and performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
