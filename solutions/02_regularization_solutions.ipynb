{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb96b065-4e7f-4836-8697-fd8137f80185",
   "metadata": {},
   "source": [
    "# Python Machine Learning: Regularization Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e63187-653f-4b31-9ed5-567a5f20b280",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenge 1: Warm-Up\n",
    "\n",
    "Before we get started, let's warm up by importing our data and performing a train test split. We've providing the importing code for you. Go ahead and split the data into train/test sets using an 80/20 split, and a random state of 23.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3bf13-a08f-43df-a10b-bde060265645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daed737-14ca-48e7-bd17-86f63c9cea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('../data/auto-mpg.csv')\n",
    "# Remove the response variable and car name\n",
    "X = data.drop(columns=['car name', 'mpg'])\n",
    "# Assign response variable to its own variable\n",
    "y = data['mpg'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f27e92-06ac-4136-bf0c-77fa8fdc5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799213f6-7e18-43fe-ae78-aa65e66e26f7",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenge 2: Benchmarking\n",
    "\n",
    "Re-run the ordinary least squares on the data using `LinearRegression`. Then, create a new ridge regression where the `alpha` penalty is set equal to zero. How do the performances of these models compare to each other? How do they compare with the original ridge regression? Be sure to compare both the training performances and test performances.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58941489-36cd-4ad2-8b0d-25cc83151519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Create models\n",
    "ridge = Ridge(\n",
    "    # Regularization penalty\n",
    "    alpha=10,\n",
    "    random_state=1)\n",
    "# Fit object\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb16cc3-6328-451a-917c-7d47a0a39cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train, y_train)\n",
    "# Ridge, no penalty\n",
    "ridge2 = Ridge(alpha=0, random_state=2) \n",
    "ridge2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116c014-77cc-4456-85b4-383d80087808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(f'Training R^2, Original Ridge: {ridge.score(X_train, y_train)}')\n",
    "print(f'Test R^2, Original Ridge: {ridge.score(X_test, y_test)}')\n",
    "print(f'Training R^2, OLS: {ols.score(X_train, y_train)}')\n",
    "print(f'Test R^2, OLS: {ols.score(X_test, y_test)}')\n",
    "print(f'Training R^2, Ridge with no penalty: {ridge2.score(X_train, y_train)}')\n",
    "print(f'Test R^2, Ridge with no penalty: {ridge2.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce10e26-c494-4a21-9274-7e70801c2594",
   "metadata": {},
   "source": [
    "- Ridge with no penalty is the same as OLS.\n",
    "- Ridge regression with a penalty has slightly worse training performance, but slightly better test performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc54c3-f936-4c95-ac6b-57c07bbc371f",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenge 3: Performing a Lasso Fit\n",
    "\n",
    "Below, we've imported the `Lasso` object from `scikit-learn` for you. Just like `Ridge`, it needs to know what the strength of the regularization penalty is before fitting to the data. \n",
    "\n",
    "Fit several Lasso models, with different regularization strengths. Try one with a regularization strength of zero, try one with a small but non-zero regularization strength, and try one with a very large regularization strength. Look at the coefficients. What do you notice?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263cd73b-3b2d-4161-b3d5-a24f1bd7488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso1 = Lasso(alpha=0.01)\n",
    "lasso1.fit(X_train, y_train)\n",
    "lasso1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7b978-efb3-4766-8f95-8c16c51bbcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2 = Lasso(alpha=10)\n",
    "lasso2.fit(X_train, y_train)\n",
    "lasso2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31efb4-933d-4fd5-9bfc-d4ec2b98ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso3 = Lasso(alpha=10000)\n",
    "lasso3.fit(X_train, y_train)\n",
    "lasso3.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
