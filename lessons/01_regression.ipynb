{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning: Regression\n",
    "\n",
    "We'll begin our foray into machine learning with **regression**. Regression is a **supervised** problem in which we use a set of features (also called independent variables or predictors) to try to predict a continuous output, or a real valued number. This is a supervised problem because we have an existing dataset in which we know what the actual outputs are for a set of samples. By showing a model enough examples, the hope is that the model can be trained to predict the output value given just the set of features, where the prediction is as close to the real value as possible.\n",
    "\n",
    "There are many ways to perform the task of regression. In this lesson, we'll focus on linear regression, and specifically ordinary least squares (OLS), which is one of the most foundational models in statistics and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto MPG Dataset\n",
    "\n",
    "We're going to use the [Auto MPG dataset](https://archive.ics.uci.edu/ml/datasets/Auto+MPG) from UCI's machine learning repository. The Auto MPG dataset contains information on city-cycle fuel consumption in miles per gallon for various types of cars. Our goal is to predict the miles per gallon of different car make and models using 7 predictors. \n",
    "\n",
    "The `auto-mpg` dataset is stored in a `.csv` file that can be accessed from the UCI repository. We've obtained a copy and made a few modifications, which we've stored in the `data` folder. We'll use `pandas` to load in the dataset by specifying the correct path. We'll start by performing some exploratory data analysis, and then build an OLS model.\n",
    "\n",
    "First, let's import (or install) some packages we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\bruno\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\bruno\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bruno\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bruno\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if you don't have these packages installed\n",
    "!pip install numpy pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the `auto-mpg` dataset using `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ford torino</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    car name   mpg  cylinders  displacement  horsepower  \\\n",
       "0  chevrolet chevelle malibu  18.0          8         307.0         130   \n",
       "1          buick skylark 320  15.0          8         350.0         165   \n",
       "2         plymouth satellite  18.0          8         318.0         150   \n",
       "3              amc rebel sst  16.0          8         304.0         150   \n",
       "4                ford torino  17.0          8         302.0         140   \n",
       "\n",
       "   weight  acceleration  model year  origin  \n",
       "0    3504          12.0          70       1  \n",
       "1    3693          11.5          70       1  \n",
       "2    3436          11.0          70       1  \n",
       "3    3433          12.0          70       1  \n",
       "4    3449          10.5          70       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/auto-mpg.csv')\n",
    "# Check out the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a \"data dictionary\", containing information about each of the variables in the dataset.\n",
    "\n",
    "| Feature     | Data Type |\n",
    "| ----------- | -------- |\n",
    "| **car name** | string (unique for each instance) | \n",
    "| **mpg**     | continuous |\n",
    "| **cylinders** | multi-valued discrete |\n",
    "| **displacement** | continuous |\n",
    "| **horsepower** |  continuous | \n",
    "| **weight** | continuous | \n",
    "| **acceleration** | continuous | \n",
    "| **model year** |  multi-valued discrete | \n",
    "| **origin** |  multi-valued discrete | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Let's start by getting familiar with our data. This is an important first step before jumping into any modeling.\n",
    "\n",
    "How many samples in the dataset do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty small dataset.\n",
    "\n",
    "Let's look at the distribution of the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = data['mpg'].hist(grid=False, bins=np.linspace(10, 50, 10))\n",
    "ax.set_xlabel('Miles per Gallon')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about how the MPG correlates with the predictors? We can use the `corr()` function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.777618</td>\n",
       "      <td>-0.805127</td>\n",
       "      <td>-0.778427</td>\n",
       "      <td>-0.832244</td>\n",
       "      <td>0.423329</td>\n",
       "      <td>0.580541</td>\n",
       "      <td>0.565209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.777618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950823</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>-0.504683</td>\n",
       "      <td>-0.345647</td>\n",
       "      <td>-0.568932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>-0.805127</td>\n",
       "      <td>0.950823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897257</td>\n",
       "      <td>0.932994</td>\n",
       "      <td>-0.543800</td>\n",
       "      <td>-0.369855</td>\n",
       "      <td>-0.614535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.778427</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.897257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864538</td>\n",
       "      <td>-0.689196</td>\n",
       "      <td>-0.416361</td>\n",
       "      <td>-0.455171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.832244</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>0.932994</td>\n",
       "      <td>0.864538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.416839</td>\n",
       "      <td>-0.309120</td>\n",
       "      <td>-0.585005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.423329</td>\n",
       "      <td>-0.504683</td>\n",
       "      <td>-0.543800</td>\n",
       "      <td>-0.689196</td>\n",
       "      <td>-0.416839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290316</td>\n",
       "      <td>0.212746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model year</th>\n",
       "      <td>0.580541</td>\n",
       "      <td>-0.345647</td>\n",
       "      <td>-0.369855</td>\n",
       "      <td>-0.416361</td>\n",
       "      <td>-0.309120</td>\n",
       "      <td>0.290316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>0.565209</td>\n",
       "      <td>-0.568932</td>\n",
       "      <td>-0.614535</td>\n",
       "      <td>-0.455171</td>\n",
       "      <td>-0.585005</td>\n",
       "      <td>0.212746</td>\n",
       "      <td>0.181528</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mpg  cylinders  displacement  horsepower    weight  \\\n",
       "mpg           1.000000  -0.777618     -0.805127   -0.778427 -0.832244   \n",
       "cylinders    -0.777618   1.000000      0.950823    0.842983  0.897527   \n",
       "displacement -0.805127   0.950823      1.000000    0.897257  0.932994   \n",
       "horsepower   -0.778427   0.842983      0.897257    1.000000  0.864538   \n",
       "weight       -0.832244   0.897527      0.932994    0.864538  1.000000   \n",
       "acceleration  0.423329  -0.504683     -0.543800   -0.689196 -0.416839   \n",
       "model year    0.580541  -0.345647     -0.369855   -0.416361 -0.309120   \n",
       "origin        0.565209  -0.568932     -0.614535   -0.455171 -0.585005   \n",
       "\n",
       "              acceleration  model year    origin  \n",
       "mpg               0.423329    0.580541  0.565209  \n",
       "cylinders        -0.504683   -0.345647 -0.568932  \n",
       "displacement     -0.543800   -0.369855 -0.614535  \n",
       "horsepower       -0.689196   -0.416361 -0.455171  \n",
       "weight           -0.416839   -0.309120 -0.585005  \n",
       "acceleration      1.000000    0.290316  0.212746  \n",
       "model year        0.290316    1.000000  0.181528  \n",
       "origin            0.212746    0.181528  1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables are pretty strongly correlated with miles per gallon, so there may be some predictive signal here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenge 1: More EDA\n",
    "\n",
    "Create the following plots, or examine the following distributions, while exploring your data:\n",
    "\n",
    "1. A histogram of the displacement.\n",
    "2. A histogram of the horsepower.\n",
    "3. A histogram of the weight.\n",
    "4. A histogram of the acceleration.\n",
    "5. What are the unique model years, and their counts?\n",
    "6. What are the unique origin values, and their counts?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Train and Test Splits\n",
    "\n",
    "Next, we'll want to split our dataset into training and test data. When creating the model, we need to make sure it only sees the training data. Then, we can examine how well it **generalizes** to data it hasn't seen before. The train and test split is a foundational concept in machine learning. Be sure you're confident you understand why we do this before moving forward!\n",
    "\n",
    "A dataset is often broken up into a feature set, or **design matrix** (typically with the variable name `X`) as well as the target or response variable `y`. Both have $D$ samples, but the design matrix will have a second dimension indicating the number of features we're using for prediction.\n",
    "\n",
    "In this case, we'll extract the output variable `mpg` from the data frame to make the `X` and `y` variables. We use a capital `X` to denote it is a `matrix` or 2-D array, and use a lowercase `y` to denote that it is a `vector`, or 1-D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 7)\n",
      "(392,)\n"
     ]
    }
   ],
   "source": [
    "# Remove the response variable and car name\n",
    "X = data.drop(columns=['car name', 'mpg'])\n",
    "# Assign response variable to its own variable\n",
    "y = data['mpg'].astype(np.float64)\n",
    "# Confidence check\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we perform the train/test split. The package `scikit-learn` is the most commonly used package for machine learning in Python. It provides a function we can easily use to perform this split. Let's import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We commonly do an 80/20 split, where 80% of the data is used for training, and the remaining 20% is used for testing. We can customize this using the parameters of the `train_test_split` function, which you can find in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "We typically split the data randomly. However, sometimes we want this random split to occur in a *reproducible* fashion. This might be when we're testing our code, and want the same random split every time. Or, during a workshop, when we want all participants to get the same split, so that the results look the same for everyone. A reproducible random fit can be done by setting the `random_state`, which is an input argument to `train_test_split`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (313, 7); y train shape: (313,)\n",
      "X test shape: (79, 7); y test shape: (79,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X train shape: {X_train.shape}; y train shape: {y_train.shape}')\n",
    "print(f'X test shape: {X_test.shape}; y test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've performed the split, let's train the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Linear Regression Model\n",
    "\n",
    "There are numerous machine learning models that can be used to model data and generate powerful predictions. These vary widely in the types of algorithms and statistical techniques that are used when building these models. Some models are purposefully built for regression problems, while others are more suited towards classification. Many models can also be used for both sets of problems with small tweaks to their algorithms.\n",
    "\n",
    "For our dataset, we'll start with the most basic (and probably most common) regression model: **linear regression, specifically Ordinary Least Squares (OLS)**. Although it's somewhat simple in structure (compared to, for example, a neural network), linear regression is a very powerful model in its own right and can be effective when applied to many regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Ordinary Least Squares?\n",
    "\n",
    "At a high level, linear regression is nothing more than finding the best straight line, or line of best fit through a set of data points that most accurately captures the pattern that exists within those data points.\n",
    "\n",
    "The most common picture people have of OLS is in the univariate case (2-D), which looks something like this:\n",
    "\n",
    "![linear-regression](../images/linear_regression_line.png)\n",
    "\n",
    "Specifically, we have *one* feature trying to predict an output. There are many points pertaining to the training samples, and we try and choose the right line that is as close to all the points as possible.\n",
    "\n",
    "However, we rarely predict with only a single feature! We're mostly in the multivariate case. In this scenario, where have many \"independent variable\" axes, but still one dependent variable axis. The \"line\" in this case turns into a **hyperplane** which tries to capture as much of the information about the multi-dimensional data points as possible:\n",
    "\n",
    "![linear-regression](../images/linear_regression_hyperplane.jpeg)\n",
    "\n",
    "In the above example, we have two features trying to predict a third dependent variable. This is as far as we can go with visualizing OLS, because humans have a hard time visualizations higher dimensions. But the intuition is basically the same: we're trying to pick a hyperplane that minimizes the distances to the data samples.\n",
    "\n",
    "When we learn an OLS model, we effectively are trying to choose the slope values (also called the weights). These are often depicted mathematically as the $\\beta$ values. There is additionally an intercept term (also called the bias term), which is really just a special case of a weight, generally denoted as $\\beta_0$. The univariate equation is probably familiar to a lot of you:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= mx + b \\\\\n",
    "  &= \\beta_0 + \\beta_1 X_1\n",
    "\\end{align}$$\n",
    "\n",
    "You may be more familiar with the $y=mx+b$ formulation, in which $m$ is the slope, and $b$ is the intercept. This is how we specify a line. All we're doing in the second line is rewriting the notation: we're calling the intercept $\\beta_0$, and the slope $\\beta_1$. We also call the feature $X_1$. We're doing this because, when we have $P$ features (i.e., the multivariate case), this can be written as:\n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_P X_P$$\n",
    "\n",
    "The goal of linear regression, then, is to find a combination of these $\\beta_i$ values such that we pass through or as close to as many data points as possible. In other words, we are trying to find the values of $\\beta$ that reduce or minimize the aggregate distance between our linear model and the data points. \n",
    "\n",
    "We can formalize this into an optimization problem and pursue a strategy that is known in machine learning as minimizing the **cost function** or **objective function** or **loss**. In the case of linear regression, the cost function we are trying to minimize is the **mean squared error (MSE)** function:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{N}\\sum_{i=1}^{N}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "where:\n",
    "* $i$ refers to the data sample,\n",
    "* $N$ is the number of samples,\n",
    "* $y_i$ is the real value of the $i$th data samples,\n",
    "* $\\hat{y}_i$ is the predicted value of the $i$th data sample, obtained from the linear model.\n",
    "\n",
    "This is where the name OLS comes from: we're trying to find the \"least squares\" solution. It's \"ordinary\" because we're making pretty simple assumptions on the model (there are variants of OLS, in which case they are no longer \"ordinary\").\n",
    "\n",
    "So, to summarize:\n",
    "* We're trying to find the best linear model for the data;\n",
    "* Finding the best linear model means finding the right $\\beta_i$ values;\n",
    "* We go about choosing these values by minimizing the mean squared error.\n",
    "The hope is, then, that these $\\beta_i$ values are good for **generalization performance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS in Practice\n",
    "\n",
    "The package `scikit-learn` makes it very easy to train a linear regression model. In general, `scikit-learn` models follow the same structure:\n",
    "* Import the model you want to train (here, `LinearRegression`).\n",
    "* Create an object for that model with chosen settings. This is *not* training the model. For example, in linear regression, you may choose a linear regression object that does or does not fit an intercept term (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) for more details).\n",
    "* Train the model using the `fit()` function, passing in the training data.\n",
    "* Evaluate the model on new data using the `predict()` and `score()` functions.\n",
    "* Examine the fitted coefficients using attributes (`coef_` and `intercept_`).\n",
    "\n",
    "Let's train the linear regression model using `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we want from sklearn's linear model module\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object for the model\n",
    "# We use the default settings\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the fit function\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done with training! That was pretty easy. Now, let's evaluate the model on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a Model\n",
    "\n",
    "When evaluating models, it's helpful to look at how it performs on both the training and test data, separately. This gives us a sense of the generalization gap, or how much we overfit to our data. If that gap is large, that means we need to make adjustments to the model in order to make sure it learns patterns that generalize well. \n",
    "\n",
    "For regression models, the `score()` method returns the amount of variance in the output variable that can be explained by the model predictions. This is known as $R^2$, or R-squared. It has a maximum of 1, with 1 being better predictive performance. There are many other performance metrics that can be used when predicting continuous variables.\n",
    "\n",
    "Let's look at the $R^2$ for the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.8317921346660861\n"
     ]
    }
   ],
   "source": [
    "print(f'Training R^2: {model.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2: 0.7356060087557543\n"
     ]
    }
   ],
   "source": [
    "print(f'Test R^2: {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there is pretty good predictive performance, with a noticeable generalization gap.\n",
    "\n",
    "Another common metric used in regression plots is the **Root Mean Squared Error (RMSE)**. This can be calculated by simply taking the square root of the MSE. In our case, we can intrepret this as the mean error made when predicting `mpg`, as RMSE is measured in the same units as the target variable.\n",
    "\n",
    "We can get a RMSE function from `scikit-learn`, but to run it, we'll need to get predictions for each sample using the `predict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the mean squared error function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 10.66662748881793\n"
     ]
    }
   ],
   "source": [
    "print(f'Train RMSE: {mean_squared_error(y_train, y_train_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 12.621614173039344\n"
     ]
    }
   ],
   "source": [
    "print(f'Test RMSE: {mean_squared_error(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the MSE directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 3.2659803258467326\n",
      "Test MSE: 3.552691117032178\n"
     ]
    }
   ],
   "source": [
    "print(f'Train MSE: {root_mean_squared_error(y_train, y_train_pred)}')\n",
    "print(f'Test MSE: {root_mean_squared_error(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be hard to try and assess model performance from MSE or RMSE directly, which is why people often use $R^2$ to evaluate predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenge 2: Mean Absolute Error\n",
    "\n",
    "Another commonly used metric in regression is the **Mean Absolute Error (MAE)**. As the name suggests, this can be calculated by taking the mean of the absolute errors. Calculate the mean absolute error on the training and test data with your trained model. We've imported the MAE for you below:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting a Model\n",
    "\n",
    "The nice thing about linear models is that they're seen as \"interpretable\". That is, we can go back  and look at the resulting $\\beta$ coefficients and exactly say what the model suggests is the relationship between the featureand output variable.\n",
    "\n",
    "We can access these coefficients by using the `coef_` attribute of the fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22757461,  0.01438493, -0.00937352, -0.00677882,  0.093271  ,\n",
       "        0.80212989,  1.62181703])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration',\n",
       "       'model year', 'origin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the first coefficient corresponding to cylinders has value equal to $-0.227$. This suggests that, for each increase in the cylinder, there is a decrease in the MPG by $0.227$. So, the coefficient gives us both a sense of the direction and magnitude of the relationship between feature and MPG.\n",
    "\n",
    "What do the other coefficients tell you about how the features relate to the output variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Challenge 3: Feature Engineering\n",
    "\n",
    "You might notice that the `origin` variable has only three values. So, it's really a categorical variable, where each sample has one of three origins. In this scenario, we've treated it like a continuous variable. \n",
    "\n",
    "How can we properly treat this variable as categorical? This is a question of preprocessing and **feature engineering**.\n",
    "\n",
    "What we can do is replace the `origin` feature with two binary variables. The first tells us whether origin is equal to 2. The second tells us whether origin is equal to 3. If both are false, that means origin is equal to 1.\n",
    "\n",
    "By fitting a linear regression with these two binary features rather than treating `origin` as continuous, we can get a better sense for how the origin impacts the MPG.\n",
    "\n",
    "Create two new binary features corresponding to origin, and then recreate the training and test data. Then, fit a linear model to the new data. What do you find about the performance and new coefficients?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Material: K-Nearest Neighbors (KNN)\n",
    "\n",
    "With more complex data, it may be difficult to capture model predictive linear relationships. In these cases, it can be useful to use models that are able to capture non-linear dependencies from the data.\n",
    "\n",
    "One such model is known as the **K-Nearest Neighbors (KNN)** algorithm. This algorithm is based off feature similarity, and uses data points that are similar to each other to predict the value of new data points. It does so by using a **distance metric** to quantify distance and therfore similarity between a set of points. In a KNN model, this distance metric can then be used to calculate an average value between $K$ data points that are most similar to the data point to be predicted in the feature space.\n",
    "\n",
    "![KNN](../images/KNN.png)\n",
    "\n",
    "The most commonly used distance metric for KNN is known as the **Eucliden distance**:\n",
    "\n",
    "$$\\text{Euclidean distance} = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$$\n",
    "\n",
    "By calculating the average Eucliden distance of the `K` nearest points, we can derive a predicted value for a given data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors regression\n",
    "\n",
    "Just like the linear regression models, `scikit-learn` provides a very easy interface to [train a KNN model](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor). A quick look at the documentation gives away the fact that there are many more settings that can be altered compared to the previous models. KNN is a model that has much greater variability in performance based on these settings. These settings - chosen before we fit the model - are often called hyperparameters. So, choosing the right hyperparameters such as the number of neighbors - or **hyperparameter tuning** - is an important step in machine learning. Again, we won't cover specific methods today, but it is an important point to remember when using KNN models in the future. \n",
    "\n",
    "Unlike linear regression models, a KNN model can be used for both regression and classification problems, so we should be sure to use the `KNNeighborsRegressor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a function you can use to automatically tune a K-nearest neighbors regressor, given some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_k_neighbors(n_neighbors, X_train, y_train, X_test, y_test):\n",
    "    # Iterate over the number of neighbors\n",
    "    for K in n_neighbors:\n",
    "        # Create nearest neighbors regressors\n",
    "        knn_reg = KNeighborsRegressor(\n",
    "            n_neighbors=K,\n",
    "            weights='uniform',  # distance weights points by inverse of their distance\n",
    "            algorithm='auto',  # out of ball_tree, kd_tree, brute\n",
    "            leaf_size=30)  # for tree algorithms\n",
    "        # Fit model\n",
    "        knn_reg.fit(X_train, y_train)\n",
    "        # Run predictions\n",
    "        knn_train_pred = knn_reg.predict(X_train)\n",
    "        knn_test_pred = knn_reg.predict(X_test)\n",
    "        # Print summary\n",
    "        print(f'K={K}: Train RMSE = {root_mean_squared_error(y_train, knn_train_pred):0.4f}; '\n",
    "              f'Test RMSE: {root_mean_squared_error(y_test, knn_test_pred):0.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2: Train RMSE = 2.6424; Test RMSE: 3.5303\n",
      "K=3: Train RMSE = 3.1774; Test RMSE: 3.4507\n",
      "K=4: Train RMSE = 3.3820; Test RMSE: 3.7358\n",
      "K=5: Train RMSE = 3.5568; Test RMSE: 3.7338\n",
      "K=6: Train RMSE = 3.6529; Test RMSE: 4.0213\n"
     ]
    }
   ],
   "source": [
    "# Example of hyperparameter tuning for the `k` neighbors value\n",
    "n_list = [2, 3, 4, 5, 6]\n",
    "tune_k_neighbors(n_list, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the performance varies greatly, but when $K=3$, we get our best performance yet!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
