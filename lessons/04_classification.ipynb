{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task in computational research is to classify an object based on a set of features. In supervised machine learning, we can give an algorithm a dataset of training examples that say \"here are specific features, and this is the target class it belongs to\". With enough training examples, a model can be built that recognizes important features in determining an object's class. This model can then be used to predict the class of an object given its known features.\n",
    "\n",
    "\n",
    "First let's import the packages that we need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penguin Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we are studying penguins in Antartica. We have a set of penguins that we have body measurements for, of three different species: Adelie, Chinstrap, and Gentoo. We are interested in being able to differentiate between these three species based on the measurements. First, let's take a look at our data set. \n",
    "\n",
    "\n",
    "Now, let's load in our preprocessed `penguins` data set.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/penguins_X_train.csv')\n",
    "X_test = pd.read_csv('../data/penguins_X_test.csv')\n",
    "y_train = pd.read_csv('../data/penguins_y_train.csv')\n",
    "y_test = pd.read_csv('../data/penguins_y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with just two penguin species: Adelie and Gentoo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[y_train['species'].isin(['Adelie','Gentoo'])].reset_index()\n",
    "X_test = X_test[y_test['species'].isin(['Adelie','Gentoo'])].reset_index()\n",
    "y_train = y_train[y_train['species'].isin(['Adelie','Gentoo'])].reset_index()\n",
    "y_test = y_test[y_test['species'].isin(['Adelie','Gentoo'])].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Accuracy\n",
    "\n",
    "Let's say that we wanted to assign a species to each unknown measured penguin. One way to do this is to assign all observations to the majority classes. The code below shows the proportion of each species in the training data.\n",
    "\n",
    "**Question:** If we want to maximize accuracy, which species label would we assign to all observations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts('species')/sum(y_train.value_counts('species'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy is our **baseline model**, and is the number that we will try to improve on with classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get to know our dataset by conducting some exploratory data analysis. We'll be using some rudimentary data analysis to see there's a relationship between the independent variables across species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we decide that body mass might be a good way to differentiate between Adelie and Gentoo penguins. We can look at a plot of the histogram to see how the distribution of this variable changes between species.\n",
    "\n",
    "**Question**: Where would you place a line to minimize the overlap in the distribution? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.histplot(data=X_train.loc[y_train['species'].isin(['Adelie','Gentoo'])],\n",
    "                x = 'body_mass_g',\n",
    "                hue = y_train['species'],kde=True,bins=20)\n",
    "#plt.axvline(.28,color= 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply this same decision boundary to the test data. \n",
    "\n",
    "**Question:** Is this still the best boundary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.histplot(data=X_test.loc[y_test['species'].isin(['Gentoo','Adelie'])],\n",
    "                x = 'body_mass_g',\n",
    "                hue = y_test['species'],kde=True,bins=20)\n",
    "#plt.axvline(.28,color= 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic goal of classification. Based on your boundary criteria, you would **classify** all each of the penguins. However there would be some error involved. We can be more confident in our classification at the far ends of the distribution, and less confident where the distributions overlap. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's figure out how to separate out these groups mathematically. For this, we will start by using an algorithm called Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic regression is a supervised classification algorithm that is used to predict a binary outcome. Similar to linear regression, this model uses coefficients or betas to make its predictions. However unlike a linear regression, its predictions range from 0 to 1, where 0 and 1 stand for 'confidently class A and B' respectively. Predictions along the middle of the line show less confidence in the prediction.\n",
    "\n",
    "The function for the logistic regression is:\n",
    "$$ p(x) = \\frac{1}{1 + e^{(-\\beta_0+\\beta_1x_1...)}}$$\n",
    "\n",
    "where $\\beta$ are the learned parameters and $x$ are the input features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a logistic regression model on the variable: `body_mass_g`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Logistic regression uses the same general steps as many other `sklearn` algorithms:\n",
    "1. Initialize Model\n",
    "2. Fit model on training data\n",
    "3. Evaluate on training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Initialize Model\n",
    "lr = LogisticRegression(max_iter=170)\n",
    "\n",
    "#2) Fit model\n",
    "lr.fit(X_train['body_mass_g'].values.reshape(-1, 1), y_train['species'])\n",
    "\n",
    "#3) Evaluate \n",
    "train_score = lr.score(X_train['body_mass_g'].values.reshape(-1, 1), y_train['species'])\n",
    "test_score = lr.score(X_test['body_mass_g'].values.reshape(-1, 1), y_test['species'])\n",
    "\n",
    "print(\"Training score:\", train_score.round(3), \"Testing score:\", test_score.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well did the model do compared to baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Logistic Regression\n",
    "\n",
    "\n",
    "The logistic regression did a pretty good job at classifying the penguins. However, we have more than just body mass to base our decision of species based on. For example, let's look at the combination of culmen depth and body mass in our data by using a scatterplot.\n",
    "\n",
    "In the two dimensional space, the intuition is that we want to draw a line that separates the classes. \n",
    "\n",
    "**Question:** Is it possible to draw a line that separates the groups? If it is, this is a **linearly seperable** problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.scatterplot(data=X_train.loc[y_train['species'].isin(['Adelie','Gentoo'])],\n",
    "                x = 'culmen_depth_mm',\n",
    "                y = 'body_mass_g',\n",
    "                hue = y_train['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the logistic model with two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=170)\n",
    "lr.fit(X_train[['body_mass_g','culmen_depth_mm']], y_train['species'])\n",
    "\n",
    "train_score = lr.score(X_train[['body_mass_g','culmen_depth_mm']], y_train['species'])\n",
    "test_score = lr.score(X_test[['body_mass_g','culmen_depth_mm']], y_test['species'])\n",
    "\n",
    "print(\"Training score = {}, testing score = {}\".format(train_score.round(3), test_score.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this doesn't happen often in real life, we got a perfect score! We could add more features to the model, but there isn't a need since our model is already behaving perfectly. Now let's take a look at the coefficients of the model. We reference the `lr.coef_` attribute to see the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coef = pd.Series(index=['body_mass_g','culmen_depth_mm'], data=lr.coef_[0])\n",
    "\n",
    "coef.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you think the *magnitude* and *sign* of the coefficients means about how these variables are related to each category?\n",
    "**Hint:** Refer back to the scatter plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've covered accuracy already but there a whole litany of other ways to evaluate the performance of a classification model.\n",
    "\n",
    "In a binary classification task, there are four major types of predictions:\n",
    "\n",
    "[Confusion Matrix (Wikipedia)](https://en.wikipedia.org/wiki/Confusion_matrix): \n",
    "- true positive (TP): A test result that correctly indicates the presence of a condition or characteristic\n",
    "- true negative (TN): A test result that correctly indicates the absence of a condition or characteristic\n",
    "- false positive (FP): A test result which wrongly indicates that a particular condition or attribute is present\n",
    "- false negative (FN): A test result which wrongly indicates that a particular condition or attribute is absent\n",
    "\n",
    "\n",
    "Accuracy, which is the most common metric used with classification can be characterized as:\n",
    "\n",
    "$$ Accuracy= \\frac{\\sum{\\text{True Positives}}+\\sum{\\text{True Negatives}}}{\\sum{\\text{Total Population}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the prediction measures above to create three helpful metrics for evaluating classification: **precision**, **recall**, and **specificity**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Precision**: \n",
    "$$\\frac{\\sum{\\text{True Positives}}}{\\sum{\\text{Predicted Positives}}}$$\n",
    "2. **Recall** (or **Sensitivity**): \n",
    "$$\\frac{\\sum{\\text{True Positives}}}{\\sum{\\text{Actual Positives}}}$$ \n",
    "3. **Specificity** (like recall for negative examples): \n",
    "$$\\frac{\\sum{\\text{True Negatives}}}{\\sum{\\text{Actual Negatives}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a confusion matrix and derive the recall and precision scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's go back to the original (not perfect) model so we can see what these rates look like.\n",
    "\n",
    "First we will retrain the model and make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train['body_mass_g'].values.reshape(-1, 1), y_train['species'])\n",
    "preds = lr.predict(X_test[['body_mass_g']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass y_test and preds into confusion_matrix\n",
    "confusion_matrix(y_test['species'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Model Evaluation\n",
    "\n",
    "1). What are the TP, FP, TN, FN in these model results?\n",
    "\n",
    "2). What is the precision and recall for this model?\n",
    "\n",
    "3). Which is more important, precision or recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your task, other metrics than accuracy might be more beneficial to understanding your model's performance. At the very least, examining the confusion matrix is a great way to get a better sense of how your model is performing across classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "Let's now include all three species of penguin that we want to differentiate between. We can turn to other models that can handle two or more classes for classification. One such example is the Decision Tree Classifier. In terms of logic, this is like a flow chart.\n",
    "\n",
    "\n",
    "In this flow chart the data is that the lamp doesn't work, and the features are information about how the lamp doesn't work. The classes is the action that is taken at the end.\n",
    "\n",
    "![Alt](https://upload.wikimedia.org/wikipedia/commons/9/91/LampFlowchart.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the ultimate goal of classification remains the same, machine learning algorithms vary widely in terms of *how* they go about this task. The neat thing about `sklearn` is that many algorithms use the same syntax, which makes comparing their performance on a task fairly straightforward. However, each model will have different underlying parameters and methods to identify the optimal split. When you are using a new model it is helpful to read up on how the model works. \n",
    "\n",
    "The documentation is a great way to do that.\n",
    "Read the [documentation](https://scikit-learn.org/stable/modules/tree.html#tree) for the Decision Tree and let's try to answer the following questions:\n",
    "\n",
    "1). What are two advantages and two disadvantages of the Decision Tree?\n",
    "2). What measure do Decision Trees use to determine optimal split?\n",
    "3). How do you import the Decision Tree from sklearn?\n",
    "\n",
    "**Decision Trees** are a classification/regression supervised learning algorithm that uses a series of splits to make its predictions.\n",
    "\n",
    "Decision Trees learn from the data by picking the feature-threshold that maximizes the information gain of the target variable. In other words it chooses a splitting point that produces the most imbalanced/pure proportions in the target variable. The goal of the model is to keep splitting until all the data in a terminal node or leaf are exclusively one class.\n",
    "\n",
    "The model iterates through a set of values for each feature and then calculate the information gain for each split and the one that produces the lowest value is the designated split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "There are many [parameters](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) for the Decision Tree Classifier. A few relevant to this notebook are described here:\n",
    "\n",
    "**criterion**: The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.\n",
    "\n",
    "**splitter**: The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.\n",
    "\n",
    "**max_depth**: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "**min_samples_split**: The minimum number of samples required to split an internal node\n",
    "\n",
    "**min_samples_leaf**: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "\n",
    "**max_features**: The number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a decision tree model on the penguins data set. We are going to start with a default DT model, meaning we're not going to pass in any parameters of our own. Like we did before, we are going to fit a model and then evaluate it on the training and testing datasets. Let's start with a single x-feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit model on the dataset\n",
    "dt.fit(X_train[['body_mass_g']], y_train['species'])\n",
    "\n",
    "# Derive the training accuracy score\n",
    "dt.score(X_train[['body_mass_g']], y_train['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "dt.score(X_test[['body_mass_g']], y_test['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Our testing score is considerably lower. When the testing score is lower than the training score, what does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of some of the parameters of the decision tree in order to help prevent overfitting of the model. Let's try a model in which we impose some constraints on the tree?\n",
    "\n",
    "**Question:** From the documentation, what is one parameter that might help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "# Fit \n",
    "dt.fit(X_train[['body_mass_g']], y_train['species'])\n",
    "\n",
    "# Evaluate\n",
    "train_score = dt.score(X_train[['body_mass_g']], y_train['species'])\n",
    "test_score = dt.score(X_test[['body_mass_g']], y_test['species'])\n",
    "\n",
    "print(\"Our training score is {} and our testing score is {}\".format(train_score.round(3), test_score.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gap between the two scores is considerably lower. Arguably we don't have an over fit model anymore. However, we could likely improve on the accuracy of this model by including more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Visualization\n",
    "\n",
    "One big advantage of the Decision Tree is that it can be visualized no matter how many features were involved.\n",
    "\n",
    "Let's retrain it with a small `max_depth` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "dt.fit(X_train[['body_mass_g']], y_train['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the first criteria used to split the decision tree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(28, 20))\n",
    "plot_tree(dt, feature_names=['body_mass_g'], class_names=[\"Adelie\", \"Chinstrap\",\"Gentoo\"], \n",
    "          filled = True, proportion=True, fontsize=18\n",
    "         );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tree, how would we make predictions about the following customers?\n",
    "\n",
    "\n",
    "    - Penguin A: Body Mass of .5\n",
    "    - Penguin B: Body Mass of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Classification with SVM\n",
    "\n",
    "Now let's try another new model. The [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html#classification) is another class of machine learning algorithm that is used for classification. \n",
    "\n",
    "Choose two features of the data set to train your model on. Then, using the documentation for the support vector machine, follow the steps to:\n",
    "- Initialize the model\n",
    "- Fit it to the training data\n",
    "- Evaluate the model on both the training and testing data\n",
    "\n",
    "Is your model underfit? Is it overfit?\n",
    "\n",
    "How does SVM fit in with the **linearly separable** problem identified in the scatter plots above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "from sklearn.svm import SVC\n",
    "X_train_subset = X_train[['feature1','feature2']]\n",
    "X_test_subset = X_test[['feature1','feature2']]\n",
    "y_train_subset = y_train['species']\n",
    "y_test_subset = y_test['species']\n",
    "\n",
    "##1) Initialize SVM\n",
    "\n",
    "##2) Train SVM on Training data \n",
    "\n",
    "##3) Evaluate SVM on Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
